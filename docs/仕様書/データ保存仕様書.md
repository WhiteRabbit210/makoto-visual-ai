# データ保存仕様書

## 目次
1. [概要](#概要)
2. [保存ポリシー](#保存ポリシー)
3. [ストレージ構成](#ストレージ構成)
4. [ディレクトリ構造](#ディレクトリ構造)
5. [チャット機能のデータ形式](#チャット機能のデータ形式)
6. [ライブラリ機能のデータ形式](#ライブラリ機能のデータ形式)
7. [音声機能のデータ形式](#音声機能のデータ形式)
8. [実装例](#実装例)
9. [取得方法](#取得方法)

## 概要

MAKOTO Visual AIの全データ保存仕様を定義します。全てのデータはサイズに関わらずBlobStorage/S3に保存されます。

## 保存ポリシー

### ⚠️⚠️⚠️ 重要：全データBlobStorage/S3保存 ⚠️⚠️⚠️

**全てのデータはサイズに関わらずBlobStorage/S3に保存します！！！**

- ✅ **正しい実装**: 小さいデータも含めて全てBlobStorage/S3に保存
- ❌ **間違った実装**: 4KB未満はDynamoDB直接保存 → **絶対にやらない！**
- ❌ **間違った実装**: TinyDBを使用 → **絶対にやらない！**
- 📝 **理由**: 
  - 統一的なバックアップとアーカイブ
  - 分析用データの一元管理
  - 監査ログとしての完全性保証
  - ストレージコストの最適化（S3の方が安価）

### 優先順位
- **BlobStorage優先**: AzureユーザーはBlobStorageを主に使用
- **S3代替**: AWSユーザーはS3を使用
- **記載順序**: ドキュメントでは「BlobStorage/S3」の順で記載

## ストレージ構成

### テナント別バケット/コンテナ
各テナントは完全に独立したストレージを保有：
- **Azure Blob**: `{tenant-id}-data`（コンテナ名）
- **AWS S3**: `{tenant-id}-data`（バケット名）

## ディレクトリ構造

### 完全なファイル格納構造
```
{tenant-bucket}/
├── {tenant_id}/                      # テナントID（最上位）
│   │
│   ├── chat/                         # チャット機能
│   │   └── {user_id}/
│   │       └── {room_id}/            # チャットルームID
│   │           ├── messages/         # メッセージ
│   │           │   └── yyyy/mm/dd/
│   │           │       ├── 09-15-23.456Z-msg_001.json
│   │           │       ├── 09-15-24.123Z-msg_002.json
│   │           │       └── 14-30-45.789Z-msg_003.json
│   │           │
│   │           ├── uploads/          # アップロードファイル
│   │           │   └── yyyy/mm/dd/
│   │           │       ├── {file_id}_{filename}
│   │           │       └── {file_id}_document.pdf
│   │           │
│   │           ├── generated/        # AI生成ファイル
│   │           │   ├── images/
│   │           │   │   └── yyyy/mm/dd/
│   │           │   │       ├── {image_id}_dalle3.png
│   │           │   │       └── {image_id}_generated.jpg
│   │           │   └── documents/
│   │           │       └── yyyy/mm/dd/
│   │           │           └── {doc_id}_report.pdf
│   │           │
│   │           └── thumbnails/       # サムネイル
│   │               ├── {file_id}_thumb.jpg
│   │               └── {image_id}_thumb.jpg
│   │
│   ├── library/                      # ライブラリ（RAG用）
│   │   └── {user_id}/
│   │       └── {library_id}/
│   │           ├── files/            # 元ファイル
│   │           │   └── {file_id}-{filename}
│   │           ├── embeddings/       # エンベディングファイル
│   │           │   └── {file_id}/
│   │           │       ├── metadata.json      # ファイルメタデータ
│   │           │       ├── chunks.parquet     # チャンクとエンベディング
│   │           │       └── index.faiss        # FAISSインデックス
│   │           └── feedback/         # RAGフィードバック
│   │               └── yyyy/mm/
│   │                   └── {feedback_id}.json
│   │
│   ├── audio/                        # 音声認識機能
│   │   └── {user_id}/
│   │       └── {audio_session_id}/   # 音声セッションID
│   │           ├── recordings/       # 音声録音
│   │           │   └── yyyy/mm/dd/
│   │           │       └── {recording_id}_audio.wav
│   │           ├── transcriptions/   # 文字起こし
│   │           │   └── yyyy/mm/dd/
│   │           │       └── {recording_id}_transcript.json
│   │           └── tts/              # 音声合成
│   │               └── yyyy/mm/dd/
│   │                   └── {tts_id}_speech.mp3
│   │
│   ├── workspace/                    # ワークスペース（将来拡張用）
│   │   └── {user_id}/
│   │       └── {workspace_id}/
│   │           ├── files/
│   │           └── metadata/
│   │
│   └── analytics/                    # 分析用データ（日次バッチ生成）
│       ├── chat/                     # チャット分析
│       │   └── daily/
│       │       └── year={yyyy}/month={mm}/day={dd}/
│       │           ├── messages.parquet      # 全メッセージ（Parquet形式）
│       │           ├── rooms.parquet         # アクティブルーム
│       │           ├── users.parquet         # アクティブユーザー
│       │           └── _metadata             # パーティションメタデータ
│       │
│       ├── library/                  # ライブラリ分析
│       │   └── daily/
│       │       └── year={yyyy}/month={mm}/day={dd}/
│       │           └── usage.parquet         # RAG利用状況
│       │
│       └── summary/                  # 集計サマリー
│           └── monthly/
│               └── year={yyyy}/month={mm}/
│                   └── report.parquet        # 月次レポート
```

## チャット機能のデータ形式

### チャットメッセージ（1発言1ファイル）
**パス形式:**
```
{tenant_id}/chat/{user_id}/{room_id}/messages/yyyy/mm/dd/hh-mm-ss.sssZ-msg_id.json
```
**例:**
```
tenant123/chat/user456/roomA/messages/2025/08/05/12-34-56.789Z-msg_abc123.json
```

**JSONファイル内容:**
```json
{
  "message_id": "msg_abc123",
  "user_id": "user456",
  "room_id": "roomA",
  "timestamp": "2025-08-05T12:34:56.789Z",
  "role": "user",
  "content": "メッセージ本文",
  
  // オプション: RAGコンテキスト
  "context": {
    "rag_sources": [
      {
        "title": "ソースタイトル",
        "source": "internal-db",
        "text": "参照されたテキスト",
        "score": 0.95
      }
    ]
  },
  
  // オプション: 添付ファイル
  "attachments": [
    {
      "type": "image",
      "url": "https://storage.blob.core.windows.net/tenant123-data/tenant123/chat/user456/roomA/uploads/2025/08/05/file_xyz789_photo.jpg",
      "thumbnail": "https://storage.blob.core.windows.net/tenant123-data/tenant123/chat/user456/roomA/thumbnails/file_xyz789_thumb.jpg",
      "name": "photo.jpg",
      "size": 2048576
    }
  ],
  
  // オプション: 生成画像
  "generated_images": [
    {
      "url": "https://storage.blob.core.windows.net/tenant123-data/tenant123/chat/user456/roomA/generated/images/2025/08/05/img_def456_dalle3.png",
      "thumbnail": "https://storage.blob.core.windows.net/tenant123-data/tenant123/chat/user456/roomA/thumbnails/img_def456_thumb.jpg",
      "prompt": "富士山の夕焼けの風景画",
      "size": "1024x1024",
      "style": "realistic"
    }
  ],
  
  // オプション: エージェント実行情報
  "agent_info": {
    "mode": "web",
    "execution_time_ms": 1250,
    "tokens_used": 145
  }
}
```

### チャット内アップロードファイル
**パス形式:**
```
{tenant_id}/chat/{user_id}/{room_id}/uploads/yyyy/mm/dd/{file_id}_{original_filename}
```
**例:**
```
tenant123/chat/user456/roomA/uploads/2025/08/05/file_xyz789_report.pdf
```

### AI生成画像（チャット内）
**パス形式:**
```
{tenant_id}/chat/{user_id}/{room_id}/generated/images/yyyy/mm/dd/{image_id}_{type}.png
```
**例:**
```
tenant123/chat/user456/roomA/generated/images/2025/08/05/img_def456_dalle3.png
```

## ライブラリ機能のデータ形式

### ライブラリファイル（RAG用元ファイル）
**パス形式:**
```
{tenant_id}/library/{user_id}/{library_id}/files/{file_id}-{filename}
```
**例:**
```
tenant123/library/user456/lib789/files/file001-manual.pdf
```

### エンベディングデータ
**パス形式:**
```
{tenant_id}/library/{user_id}/{library_id}/embeddings/{file_id}/
├── metadata.json      # ファイルメタデータ
├── chunks.parquet     # チャンクとエンベディング（OpenAI text-embedding-3-large）
└── index.faiss        # FAISSインデックス（オプション）
```

**metadata.json内容:**
```json
{
  "file_id": "file001",
  "filename": "manual.pdf",
  "content_type": "application/pdf",
  "size": 1048576,
  "uploaded_at": "2025-08-05T10:00:00Z",
  "vectorized_at": "2025-08-05T10:05:00Z",
  "chunk_count": 42,
  "embedding_model": "text-embedding-3-large",
  "embedding_dimension": 3072,
  "total_tokens": 15000
}
```

**chunks.parquet構造:**
```
- chunk_id: string
- chunk_index: int
- text: string
- embedding: array<float>[3072]  # text-embedding-3-large
- metadata: json
```

### RAGフィードバック
**パス形式:**
```
{tenant_id}/library/{user_id}/{library_id}/feedback/yyyy/mm/{feedback_id}.json
```
**例:**
```
tenant123/library/user456/lib789/feedback/2025/08/feedback_abc123.json
```

## 音声機能のデータ形式

### 音声録音ファイル
**パス形式:**
```
{tenant_id}/audio/{user_id}/{audio_session_id}/recordings/yyyy/mm/dd/{recording_id}_audio.wav
```
**例:**
```
tenant123/audio/user456/session789/recordings/2025/08/05/rec001_audio.wav
```

### 音声文字起こし
**パス形式:**
```
{tenant_id}/audio/{user_id}/{audio_session_id}/transcriptions/yyyy/mm/dd/{recording_id}_transcript.json
```
**例:**
```
tenant123/audio/user456/session789/transcriptions/2025/08/05/rec001_transcript.json
```

**transcript.json内容:**
```json
{
  "recording_id": "rec001",
  "audio_session_id": "session789",
  "user_id": "user456",
  "timestamp": "2025-08-05T14:30:00Z",
  "duration_seconds": 120,
  "language": "ja-JP",
  "model": "whisper-large-v3",
  "transcript": "文字起こしされたテキスト...",
  "confidence": 0.95,
  "segments": [
    {
      "start": 0.0,
      "end": 5.2,
      "text": "こんにちは",
      "confidence": 0.98
    }
  ]
}
```

### 音声合成（TTS）
**パス形式:**
```
{tenant_id}/audio/{user_id}/{audio_session_id}/tts/yyyy/mm/dd/{tts_id}_speech.mp3
```
**例:**
```
tenant123/audio/user456/session789/tts/2025/08/05/tts001_speech.mp3
```

## 実装例

### Python実装（チャットメッセージ保存）
```python
async def save_chat_message(tenant_id: str, user_id: str, room_id: str, message: dict):
    """チャットメッセージをBlobStorage/S3に保存"""
    import json
    from datetime import datetime
    from services.storage_service import storage_service
    
    # タイムスタンプとキーの生成
    timestamp = datetime.now()
    date_path = timestamp.strftime("%Y/%m/%d")
    time_str = timestamp.strftime("%H-%M-%S.%f")[:-3] + "Z"
    message_id = message.get('id', str(uuid.uuid4()))
    
    # ストレージキー
    storage_key = f"{tenant_id}/chat/{user_id}/{room_id}/messages/{date_path}/{time_str}-{message_id}.json"
    
    # メッセージデータ
    message_data = {
        "message_id": message_id,
        "user_id": user_id,
        "room_id": room_id,
        "timestamp": timestamp.isoformat(),
        "role": message['role'],
        "content": message['content']
    }
    
    # オプションフィールドの追加
    for field in ['attachments', 'generated_images', 'context', 'agent_info']:
        if field in message:
            message_data[field] = message[field]
    
    # JSONとして保存
    message_json = json.dumps(message_data, ensure_ascii=False, indent=2)
    
    result = await storage_service.put_object(storage_key, message_json)
    
    if result['success']:
        print(f"メッセージを保存しました: {storage_key}")
    else:
        raise Exception(f"保存失敗: {result.get('error')}")
    
    return message_data
```

### ライブラリファイルのエンベディング保存
```python
async def save_embeddings(tenant_id: str, user_id: str, library_id: str, 
                          file_id: str, chunks_data: list):
    """エンベディングデータを保存"""
    import pandas as pd
    import numpy as np
    
    # Parquet形式でチャンクとエンベディングを保存
    df = pd.DataFrame(chunks_data)
    
    # ストレージパス
    embeddings_path = f"{tenant_id}/library/{user_id}/{library_id}/embeddings/{file_id}/"
    
    # chunks.parquetとして保存
    parquet_key = f"{embeddings_path}chunks.parquet"
    parquet_buffer = df.to_parquet()
    
    await storage_service.upload_binary(
        key=parquet_key,
        data=parquet_buffer,
        content_type='application/octet-stream'
    )
    
    # メタデータを保存
    metadata = {
        "file_id": file_id,
        "chunk_count": len(chunks_data),
        "embedding_model": "text-embedding-3-large",
        "embedding_dimension": 3072,
        "vectorized_at": datetime.now().isoformat()
    }
    
    metadata_key = f"{embeddings_path}metadata.json"
    await storage_service.put_object(
        key=metadata_key,
        content=json.dumps(metadata, ensure_ascii=False, indent=2)
    )
    
    print(f"エンベディングを保存: {embeddings_path}")
```

## 分析用データ（日次バッチ）

### Parquet形式での分析データ

**概要：**
アプリケーション用のJSON形式とは別に、分析用にParquet形式のデータを日次バッチで生成します。

**Parquet形式のメリット：**
- **圧縮率が高い**：JSONの10分の1程度のサイズ
- **分析が高速**：列指向形式でAthena/Synapseに最適
- **コスト効率**：必要な列のみ読み込むため、スキャンコストが低い

### 日次バッチ処理

**実行タイミング：**
- 毎日深夜2:00 UTC（日本時間11:00）
- 前日分のデータを集計

**バッチ処理の実装例：**
```python
import pandas as pd
from datetime import datetime, timedelta
import pyarrow.parquet as pq

async def daily_batch_job(tenant_id: str, target_date: str):
    """日次バッチでParquet形式に変換"""
    
    # 1. 対象日のJSONメッセージを収集
    prefix = f"{tenant_id}/chat/"
    messages = []
    
    # 全ユーザーの対象日メッセージを収集
    async for obj in storage_service.list_objects_paginated(prefix):
        if f"/{target_date}/" in obj['key'] and obj['key'].endswith('.json'):
            content = await storage_service.get_object(obj['key'])
            message = json.loads(content)
            messages.append(message)
    
    # 2. DataFrameに変換
    df = pd.DataFrame(messages)
    
    # 3. 分析用カラムを追加
    df['date'] = pd.to_datetime(df['timestamp']).dt.date
    df['hour'] = pd.to_datetime(df['timestamp']).dt.hour
    df['message_length'] = df['content'].str.len()
    df['has_attachments'] = df['attachments'].notna()
    
    # 4. Parquet形式で保存（Hiveスタイルパーティション）
    year, month, day = target_date.split('/')
    parquet_path = f"{tenant_id}/analytics/chat/daily/year={year}/month={month}/day={day}/messages.parquet"
    
    # 圧縮オプション付きで保存
    df.to_parquet(
        parquet_path,
        compression='snappy',  # 高速圧縮
        index=False
    )
    
    # 5. 集計データも生成
    summary_df = pd.DataFrame([{
        'date': target_date,
        'total_messages': len(df),
        'unique_users': df['user_id'].nunique(),
        'unique_rooms': df['room_id'].nunique(),
        'avg_message_length': df['message_length'].mean()
    }])
    
    summary_path = f"{tenant_id}/analytics/chat/daily/year={year}/month={month}/day={day}/summary.parquet"
    summary_df.to_parquet(summary_path)
    
    return {
        'processed_messages': len(df),
        'file_size': get_file_size(parquet_path)
    }
```

### Athena/Synapseでの分析

**テーブル定義（Athena）：**
```sql
CREATE EXTERNAL TABLE IF NOT EXISTS chat_messages (
    message_id string,
    user_id string,
    room_id string,
    timestamp timestamp,
    role string,
    content string,
    message_length int,
    has_attachments boolean
)
PARTITIONED BY (
    year string,
    month string,
    day string
)
STORED AS PARQUET
LOCATION 's3://{bucket}/{tenant_id}/analytics/chat/daily/'
```

**分析クエリ例：**
```sql
-- テナント全体の日別メッセージ数
SELECT 
    year, month, day,
    COUNT(*) as message_count,
    COUNT(DISTINCT user_id) as active_users,
    COUNT(DISTINCT room_id) as active_rooms
FROM chat_messages
WHERE year = '2025' AND month = '08'
GROUP BY year, month, day
ORDER BY year, month, day;

-- 特定ユーザーの利用分析
SELECT 
    user_id,
    DATE(timestamp) as date,
    COUNT(*) as messages,
    AVG(message_length) as avg_length,
    SUM(CASE WHEN has_attachments THEN 1 ELSE 0 END) as attachments_count
FROM chat_messages
WHERE user_id = 'user456'
    AND year = '2025' AND month = '08'
GROUP BY user_id, DATE(timestamp);

-- 時間帯別の利用パターン
SELECT 
    hour,
    COUNT(*) as message_count,
    COUNT(DISTINCT user_id) as unique_users
FROM chat_messages
WHERE year = '2025' AND month = '08'
GROUP BY hour
ORDER BY hour;
```

### コスト見積もり

**月間100万メッセージの場合：**

| 項目 | 料金 | 説明 |
|------|------|------|
| Lambda/Functions実行 | $5/月 | 5分×30日の処理 |
| S3読み取り | $3/月 | JSON読み込み |
| S3書き込み | $1/月 | Parquet保存 |
| Athenaクエリ | $5/月 | 1日10クエリ想定 |
| **合計** | **約$14/月** | |

**コスト削減のポイント：**
- Parquet圧縮により保存容量を90%削減
- 列指向形式によりAthenaスキャン量を削減
- パーティションにより必要な日付のみスキャン

## 取得方法

### チャットメッセージの取得
```python
async def get_chat_messages(tenant_id: str, user_id: str, room_id: str, limit: int = 50):
    """チャットメッセージを取得"""
    from services.storage_service import storage_service
    
    # プレフィックス
    prefix = f"{tenant_id}/chat/{user_id}/{room_id}/messages/"
    
    # オブジェクトリストを取得
    result = await storage_service.list_objects(prefix=prefix, limit=limit)
    
    messages = []
    if result.get('success') and result.get('objects'):
        # 各メッセージファイルを読み込む
        for obj in result['objects']:
            key = obj['key']
            content = await storage_service.get_object(key)
            
            if content:
                try:
                    message = json.loads(content)
                    messages.append(message)
                except json.JSONDecodeError:
                    print(f"パース失敗: {key}")
                    continue
        
        # タイムスタンプでソート（古い順）
        messages.sort(key=lambda x: x.get('timestamp', ''))
    
    return messages
```

### ライブラリのエンベディング検索
```python
async def search_embeddings(tenant_id: str, user_id: str, library_id: str, 
                           query_embedding: np.ndarray, top_k: int = 10):
    """エンベディングを検索"""
    import pandas as pd
    import faiss
    
    # ライブラリ内の全エンベディングファイルを取得
    prefix = f"{tenant_id}/library/{user_id}/{library_id}/embeddings/"
    result = await storage_service.list_objects(prefix=prefix)
    
    all_chunks = []
    
    for obj in result.get('objects', []):
        if obj['key'].endswith('chunks.parquet'):
            # Parquetファイルを読み込み
            content = await storage_service.get_object(obj['key'])
            df = pd.read_parquet(io.BytesIO(content))
            all_chunks.append(df)
    
    if not all_chunks:
        return []
    
    # 全チャンクを結合
    combined_df = pd.concat(all_chunks, ignore_index=True)
    embeddings = np.array(combined_df['embedding'].tolist()).astype('float32')
    
    # FAISSインデックス構築
    dimension = 3072  # text-embedding-3-large
    index = faiss.IndexFlatIP(dimension)
    faiss.normalize_L2(embeddings)
    index.add(embeddings)
    
    # 検索実行
    faiss.normalize_L2(query_embedding.reshape(1, -1))
    scores, indices = index.search(query_embedding.reshape(1, -1), top_k)
    
    # 結果を返す
    results = []
    for idx, score in zip(indices[0], scores[0]):
        chunk = combined_df.iloc[idx]
        results.append({
            'chunk_id': chunk['chunk_id'],
            'text': chunk['text'],
            'score': float(score)
        })
    
    return results
```

## KVM（Key-Value Management）連携

### 概要
メタデータはDynamoDB/CosmosDB（KVM）で管理し、実データはBlobStorage/S3に保存するハイブリッド構成です。

### KVMに保持するメタデータ

#### チャットルームメタ情報
| 項目名 | 説明 | 備考 |
|--------|------|------|
| PK | パーティションキー | `TENANT#{tenant_id}#USER#{user_id}` |
| SK | ソートキー | `CHAT#{room_id}` |
| title | チャットタイトル | |
| created_at | 作成日時 | ISO 8601形式 |
| updated_at | 更新日時 | 最終発言時に更新 |
| message_count | メッセージ数 | |
| last_message | 直近メッセージ | 本文プレビュー（50文字）、時刻、送信者 |
| unread_count | 未読数 | オプション |
| settings | チャット設定 | system_prompt、temperature等 |
| status | ステータス | active/archived/deleted |

```python
# 実例
{
    'PK': 'TENANT#tenant123#USER#user456',
    'SK': 'CHAT#roomA',
    'title': 'ミツイワ社長について',
    'created_at': '2025-08-05T10:00:00Z',
    'updated_at': '2025-08-05T12:34:56Z',
    'message_count': 42,
    'last_message': {
        'text': '質問ありがとうございます...',  # 50文字まで
        'timestamp': '2025-08-05T12:34:56Z',
        'role': 'assistant'
    },
    'unread_count': 0,
    'status': 'active'
}
```

#### ライブラリメタ情報
| 項目名 | 説明 | 備考 |
|--------|------|------|
| PK | パーティションキー | `TENANT#{tenant_id}#USER#{user_id}` |
| SK | ソートキー | `LIBRARY#{library_id}` |
| name | ライブラリ名 | |
| description | 説明 | |
| created_at | 作成日時 | |
| updated_at | 更新日時 | |
| file_count | ファイル数 | |
| total_chunks | エンベディング数 | |
| visibility | 公開範囲 | private/shared/public |
| vector_status | ベクトル化進捗 | pending/processing/completed/failed |

#### 音声セッションメタ情報
| 項目名 | 説明 | 備考 |
|--------|------|------|
| PK | パーティションキー | `TENANT#{tenant_id}#USER#{user_id}` |
| SK | ソートキー | `AUDIO#{audio_session_id}` |
| created_at | 開始日時 | |
| updated_at | 最終更新 | |
| total_recordings | 録音数 | |
| transcription_status | 文字起こし進捗 | pending/processing/completed |

### KVMに保存しないもの
- ❌ チャットメッセージ本文
- ❌ ファイル本体
- ❌ 音声ファイル本体
- ❌ エンベディングデータ本体
- ❌ 画像・ドキュメント本体

### 連携運用フロー

#### 新規チャットルーム作成時
```python
# 1. KVMにメタデータ登録
await kvm.put_item({
    'PK': f'TENANT#{tenant_id}#USER#{user_id}',
    'SK': f'CHAT#{room_id}',
    'title': title,
    'created_at': datetime.now().isoformat(),
    'updated_at': datetime.now().isoformat(),
    'message_count': 0,
    'status': 'active'
})

# 2. ストレージにディレクトリ準備（初回メッセージ時でも可）
```

#### メッセージ投稿時
```python
# 1. ストレージにメッセージ保存
message_key = f"{tenant_id}/chat/{user_id}/{room_id}/messages/{date_path}/{time}-{msg_id}.json"
await storage.put_object(message_key, message_json)

# 2. KVMのメタデータ更新（atomic）
await kvm.update_item(
    Key={'PK': f'TENANT#{tenant_id}#USER#{user_id}', 'SK': f'CHAT#{room_id}'},
    UpdateExpression='SET updated_at = :now, message_count = message_count + :inc, last_message = :msg',
    ExpressionAttributeValues={
        ':now': datetime.now().isoformat(),
        ':inc': 1,
        ':msg': {
            'text': content[:50] + '...' if len(content) > 50 else content,
            'timestamp': datetime.now().isoformat(),
            'role': role
        }
    }
)
```

#### チャット一覧取得時
```python
# KVMから高速取得（〜10ms）
response = await kvm.query(
    KeyConditionExpression='PK = :pk AND begins_with(SK, :sk)',
    ExpressionAttributeValues={
        ':pk': f'TENANT#{tenant_id}#USER#{user_id}',
        ':sk': 'CHAT#'
    },
    ScanIndexForward=False,  # 新しい順
    Limit=100
)
# last_messageやunread_countが即座に取得可能
```

#### メッセージ履歴取得時
```python
# ストレージから必要な分だけ取得（〜200ms）
prefix = f"{tenant_id}/chat/{user_id}/{room_id}/messages/"
messages = await storage.list_and_get_objects(prefix, limit=50)
```

## 制限事項

### ファイルサイズ制限
- **チャットアップロード**: 最大10MB
- **ライブラリファイル**: 最大50MB
- **音声録音**: 最大30分（約300MB）
- **生成画像**: DALL-E 3の制限に準拠（1024x1024）
- **サムネイル**: 最大200x200ピクセル、JPEG形式

### レート制限
- **1分あたりのメッセージ数**: 10
- **1時間あたりのメッセージ数**: 100
- **1時間あたりのファイルアップロード数**: 20
- **OpenAI Embedding API**: 3,000 RPM / 1,000,000 TPM

## 注意事項

### やってはいけないこと
1. **TinyDBの使用** - 開発環境でも使用禁止
2. **DynamoDBへの直接保存** - データ本体は保存しない（メタデータのみ）
3. **サイズによる保存先の分岐** - 全て一律BlobStorage/S3へ
4. **メッセージインデックスの作成** - 最大500件程度なので不要

### パフォーマンス考慮
- チャットルーム毎の最大メッセージ数：約500件
- ライブラリ毎の推奨チャンク数：〜50,000件（FAISSの場合）
- 大規模な場合はPinecone/Weaviateなどの専用ベクトルDBを検討

### セキュリティ
- テナントごとにプレフィックス`{tenant_id}/`でアクセス制限
- ユーザーごとにプレフィックス`{user_id}/`でさらに制限
- 署名付きURL/SASトークンで一時的アクセス許可
- クロステナントアクセスは完全に禁止
- アップロードファイルのウイルススキャン推奨