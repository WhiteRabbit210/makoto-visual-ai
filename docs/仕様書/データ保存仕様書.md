# ãƒ‡ãƒ¼ã‚¿ä¿å­˜ä»•æ§˜æ›¸

## ç›®æ¬¡
1. [æ¦‚è¦](#æ¦‚è¦)
2. [ä¿å­˜ãƒãƒªã‚·ãƒ¼](#ä¿å­˜ãƒãƒªã‚·ãƒ¼)
3. [ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ§‹æˆ](#ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ§‹æˆ)
4. [ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ](#ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ )
5. [ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼](#ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼)
6. [ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ©Ÿèƒ½ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼](#ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ©Ÿèƒ½ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼)
7. [éŸ³å£°æ©Ÿèƒ½ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼](#éŸ³å£°æ©Ÿèƒ½ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼)
8. [å®Ÿè£…ä¾‹](#å®Ÿè£…ä¾‹)
9. [å–å¾—æ–¹æ³•](#å–å¾—æ–¹æ³•)

## æ¦‚è¦

MAKOTO Visual AIã®å…¨ãƒ‡ãƒ¼ã‚¿ä¿å­˜ä»•æ§˜ã‚’å®šç¾©ã—ã¾ã™ã€‚å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã¯ã‚µã‚¤ã‚ºã«é–¢ã‚ã‚‰ãšBlobStorage/S3ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚

## ä¿å­˜ãƒãƒªã‚·ãƒ¼

### âš ï¸âš ï¸âš ï¸ é‡è¦ï¼šå…¨ãƒ‡ãƒ¼ã‚¿BlobStorage/S3ä¿å­˜ âš ï¸âš ï¸âš ï¸

**å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã¯ã‚µã‚¤ã‚ºã«é–¢ã‚ã‚‰ãšBlobStorage/S3ã«ä¿å­˜ã—ã¾ã™ï¼ï¼ï¼**

- âœ… **æ­£ã—ã„å®Ÿè£…**: å°ã•ã„ãƒ‡ãƒ¼ã‚¿ã‚‚å«ã‚ã¦å…¨ã¦BlobStorage/S3ã«ä¿å­˜
- âŒ **é–“é•ã£ãŸå®Ÿè£…**: 4KBæœªæº€ã¯DynamoDBç›´æ¥ä¿å­˜ â†’ **çµ¶å¯¾ã«ã‚„ã‚‰ãªã„ï¼**
- âŒ **é–“é•ã£ãŸå®Ÿè£…**: TinyDBã‚’ä½¿ç”¨ â†’ **çµ¶å¯¾ã«ã‚„ã‚‰ãªã„ï¼**
- ğŸ“ **ç†ç”±**: 
  - çµ±ä¸€çš„ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
  - åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã®ä¸€å…ƒç®¡ç†
  - ç›£æŸ»ãƒ­ã‚°ã¨ã—ã¦ã®å®Œå…¨æ€§ä¿è¨¼
  - ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆã®æœ€é©åŒ–ï¼ˆS3ã®æ–¹ãŒå®‰ä¾¡ï¼‰

### å„ªå…ˆé †ä½
- **BlobStorageå„ªå…ˆ**: Azureãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯BlobStorageã‚’ä¸»ã«ä½¿ç”¨
- **S3ä»£æ›¿**: AWSãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯S3ã‚’ä½¿ç”¨
- **è¨˜è¼‰é †åº**: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€ŒBlobStorage/S3ã€ã®é †ã§è¨˜è¼‰

## ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ§‹æˆ

### ãƒ†ãƒŠãƒ³ãƒˆåˆ¥ãƒã‚±ãƒƒãƒˆ/ã‚³ãƒ³ãƒ†ãƒŠ
å„ãƒ†ãƒŠãƒ³ãƒˆã¯å®Œå…¨ã«ç‹¬ç«‹ã—ãŸã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ä¿æœ‰ï¼š
- **Azure Blob**: `{tenant-id}-data`ï¼ˆã‚³ãƒ³ãƒ†ãƒŠåï¼‰
- **AWS S3**: `{tenant-id}-data`ï¼ˆãƒã‚±ãƒƒãƒˆåï¼‰

## ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

### å®Œå…¨ãªãƒ•ã‚¡ã‚¤ãƒ«æ ¼ç´æ§‹é€ 
```
{tenant-bucket}/
â”œâ”€â”€ {tenant_id}/                      # ãƒ†ãƒŠãƒ³ãƒˆIDï¼ˆæœ€ä¸Šä½ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ chat/                         # ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½
â”‚   â”‚   â””â”€â”€ {user_id}/
â”‚   â”‚       â””â”€â”€ {room_id}/            # ãƒãƒ£ãƒƒãƒˆãƒ«ãƒ¼ãƒ ID
â”‚   â”‚           â”œâ”€â”€ messages/         # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
â”‚   â”‚           â”‚   â””â”€â”€ yyyy/mm/dd/
â”‚   â”‚           â”‚       â”œâ”€â”€ 09-15-23.456Z-msg_001.json
â”‚   â”‚           â”‚       â”œâ”€â”€ 09-15-24.123Z-msg_002.json
â”‚   â”‚           â”‚       â””â”€â”€ 14-30-45.789Z-msg_003.json
â”‚   â”‚           â”‚
â”‚   â”‚           â”œâ”€â”€ uploads/          # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”‚           â”‚   â””â”€â”€ yyyy/mm/dd/
â”‚   â”‚           â”‚       â”œâ”€â”€ {file_id}_{filename}
â”‚   â”‚           â”‚       â””â”€â”€ {file_id}_document.pdf
â”‚   â”‚           â”‚
â”‚   â”‚           â”œâ”€â”€ generated/        # AIç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”‚           â”‚   â”œâ”€â”€ images/
â”‚   â”‚           â”‚   â”‚   â””â”€â”€ yyyy/mm/dd/
â”‚   â”‚           â”‚   â”‚       â”œâ”€â”€ {image_id}_dalle3.png
â”‚   â”‚           â”‚   â”‚       â””â”€â”€ {image_id}_generated.jpg
â”‚   â”‚           â”‚   â””â”€â”€ documents/
â”‚   â”‚           â”‚       â””â”€â”€ yyyy/mm/dd/
â”‚   â”‚           â”‚           â””â”€â”€ {doc_id}_report.pdf
â”‚   â”‚           â”‚
â”‚   â”‚           â””â”€â”€ thumbnails/       # ã‚µãƒ ãƒã‚¤ãƒ«
â”‚   â”‚               â”œâ”€â”€ {file_id}_thumb.jpg
â”‚   â”‚               â””â”€â”€ {image_id}_thumb.jpg
â”‚   â”‚
â”‚   â”œâ”€â”€ library/                      # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆRAGç”¨ï¼‰
â”‚   â”‚   â””â”€â”€ {user_id}/
â”‚   â”‚       â””â”€â”€ {library_id}/
â”‚   â”‚           â”œâ”€â”€ files/            # å…ƒãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”‚           â”‚   â””â”€â”€ {file_id}-{filename}
â”‚   â”‚           â”œâ”€â”€ embeddings/       # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”‚           â”‚   â””â”€â”€ {file_id}/
â”‚   â”‚           â”‚       â”œâ”€â”€ metadata.json      # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
â”‚   â”‚           â”‚       â”œâ”€â”€ chunks.parquet     # ãƒãƒ£ãƒ³ã‚¯ã¨ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°
â”‚   â”‚           â”‚       â””â”€â”€ index.faiss        # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
â”‚   â”‚           â””â”€â”€ feedback/         # RAGãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
â”‚   â”‚               â””â”€â”€ yyyy/mm/
â”‚   â”‚                   â””â”€â”€ {feedback_id}.json
â”‚   â”‚
â”‚   â”œâ”€â”€ audio/                        # éŸ³å£°èªè­˜æ©Ÿèƒ½
â”‚   â”‚   â””â”€â”€ {user_id}/
â”‚   â”‚       â””â”€â”€ {audio_session_id}/   # éŸ³å£°ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
â”‚   â”‚           â”œâ”€â”€ recordings/       # éŸ³å£°éŒ²éŸ³
â”‚   â”‚           â”‚   â””â”€â”€ yyyy/mm/dd/
â”‚   â”‚           â”‚       â””â”€â”€ {recording_id}_audio.wav
â”‚   â”‚           â”œâ”€â”€ transcriptions/   # æ–‡å­—èµ·ã“ã—
â”‚   â”‚           â”‚   â””â”€â”€ yyyy/mm/dd/
â”‚   â”‚           â”‚       â””â”€â”€ {recording_id}_transcript.json
â”‚   â”‚           â””â”€â”€ tts/              # éŸ³å£°åˆæˆ
â”‚   â”‚               â””â”€â”€ yyyy/mm/dd/
â”‚   â”‚                   â””â”€â”€ {tts_id}_speech.mp3
â”‚   â”‚
â”‚   â”œâ”€â”€ workspace/                    # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ï¼ˆå°†æ¥æ‹¡å¼µç”¨ï¼‰
â”‚   â”‚   â””â”€â”€ {user_id}/
â”‚   â”‚       â””â”€â”€ {workspace_id}/
â”‚   â”‚           â”œâ”€â”€ files/
â”‚   â”‚           â””â”€â”€ metadata/
â”‚   â”‚
â”‚   â””â”€â”€ analytics/                    # åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¥æ¬¡ãƒãƒƒãƒç”Ÿæˆï¼‰
â”‚       â”œâ”€â”€ chat/                     # ãƒãƒ£ãƒƒãƒˆåˆ†æ
â”‚       â”‚   â””â”€â”€ daily/
â”‚       â”‚       â””â”€â”€ year={yyyy}/month={mm}/day={dd}/
â”‚       â”‚           â”œâ”€â”€ messages.parquet      # å…¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆParquetå½¢å¼ï¼‰
â”‚       â”‚           â”œâ”€â”€ rooms.parquet         # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ«ãƒ¼ãƒ 
â”‚       â”‚           â”œâ”€â”€ users.parquet         # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼
â”‚       â”‚           â””â”€â”€ _metadata             # ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
â”‚       â”‚
â”‚       â”œâ”€â”€ library/                  # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåˆ†æ
â”‚       â”‚   â””â”€â”€ daily/
â”‚       â”‚       â””â”€â”€ year={yyyy}/month={mm}/day={dd}/
â”‚       â”‚           â””â”€â”€ usage.parquet         # RAGåˆ©ç”¨çŠ¶æ³
â”‚       â”‚
â”‚       â””â”€â”€ summary/                  # é›†è¨ˆã‚µãƒãƒªãƒ¼
â”‚           â””â”€â”€ monthly/
â”‚               â””â”€â”€ year={yyyy}/month={mm}/
â”‚                   â””â”€â”€ report.parquet        # æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆ
```

## ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼

### ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆ1ç™ºè¨€1ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
**ãƒ‘ã‚¹å½¢å¼:**
```
{tenant_id}/chat/{user_id}/{room_id}/messages/yyyy/mm/dd/hh-mm-ss.sssZ-msg_id.json
```
**ä¾‹:**
```
tenant123/chat/user456/roomA/messages/2025/08/05/12-34-56.789Z-msg_abc123.json
```

**JSONãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹:**
```json
{
  "message_id": "msg_abc123",
  "user_id": "user456",
  "room_id": "roomA",
  "timestamp": "2025-08-05T12:34:56.789Z",
  "role": "user",
  "content": "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æœ¬æ–‡",
  
  // ã‚ªãƒ—ã‚·ãƒ§ãƒ³: RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
  "context": {
    "rag_sources": [
      {
        "title": "ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«",
        "source": "internal-db",
        "text": "å‚ç…§ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ",
        "score": 0.95
      }
    ]
  },
  
  // ã‚ªãƒ—ã‚·ãƒ§ãƒ³: æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«
  "attachments": [
    {
      "type": "image",
      "url": "https://storage.blob.core.windows.net/tenant123-data/tenant123/chat/user456/roomA/uploads/2025/08/05/file_xyz789_photo.jpg",
      "thumbnail": "https://storage.blob.core.windows.net/tenant123-data/tenant123/chat/user456/roomA/thumbnails/file_xyz789_thumb.jpg",
      "name": "photo.jpg",
      "size": 2048576
    }
  ],
  
  // ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ç”Ÿæˆç”»åƒ
  "generated_images": [
    {
      "url": "https://storage.blob.core.windows.net/tenant123-data/tenant123/chat/user456/roomA/generated/images/2025/08/05/img_def456_dalle3.png",
      "thumbnail": "https://storage.blob.core.windows.net/tenant123-data/tenant123/chat/user456/roomA/thumbnails/img_def456_thumb.jpg",
      "prompt": "å¯Œå£«å±±ã®å¤•ç„¼ã‘ã®é¢¨æ™¯ç”»",
      "size": "1024x1024",
      "style": "realistic"
    }
  ],
  
  // ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œæƒ…å ±
  "agent_info": {
    "mode": "web",
    "execution_time_ms": 1250,
    "tokens_used": 145
  }
}
```

### ãƒãƒ£ãƒƒãƒˆå†…ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«
**ãƒ‘ã‚¹å½¢å¼:**
```
{tenant_id}/chat/{user_id}/{room_id}/uploads/yyyy/mm/dd/{file_id}_{original_filename}
```
**ä¾‹:**
```
tenant123/chat/user456/roomA/uploads/2025/08/05/file_xyz789_report.pdf
```

### AIç”Ÿæˆç”»åƒï¼ˆãƒãƒ£ãƒƒãƒˆå†…ï¼‰
**ãƒ‘ã‚¹å½¢å¼:**
```
{tenant_id}/chat/{user_id}/{room_id}/generated/images/yyyy/mm/dd/{image_id}_{type}.png
```
**ä¾‹:**
```
tenant123/chat/user456/roomA/generated/images/2025/08/05/img_def456_dalle3.png
```

## ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ©Ÿèƒ½ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼

### ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆRAGç”¨å…ƒãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
**ãƒ‘ã‚¹å½¢å¼:**
```
{tenant_id}/library/{user_id}/{library_id}/files/{file_id}-{filename}
```
**ä¾‹:**
```
tenant123/library/user456/lib789/files/file001-manual.pdf
```

### ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
**ãƒ‘ã‚¹å½¢å¼:**
```
{tenant_id}/library/{user_id}/{library_id}/embeddings/{file_id}/
â”œâ”€â”€ metadata.json      # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
â”œâ”€â”€ chunks.parquet     # ãƒãƒ£ãƒ³ã‚¯ã¨ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆOpenAI text-embedding-3-largeï¼‰
â””â”€â”€ index.faiss        # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
```

**metadata.jsonå†…å®¹:**
```json
{
  "file_id": "file001",
  "filename": "manual.pdf",
  "content_type": "application/pdf",
  "size": 1048576,
  "uploaded_at": "2025-08-05T10:00:00Z",
  "vectorized_at": "2025-08-05T10:05:00Z",
  "chunk_count": 42,
  "embedding_model": "text-embedding-3-large",
  "embedding_dimension": 3072,
  "total_tokens": 15000
}
```

**chunks.parquetæ§‹é€ :**
```
- chunk_id: string
- chunk_index: int
- text: string
- embedding: array<float>[3072]  # text-embedding-3-large
- metadata: json
```

### RAGãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
**ãƒ‘ã‚¹å½¢å¼:**
```
{tenant_id}/library/{user_id}/{library_id}/feedback/yyyy/mm/{feedback_id}.json
```
**ä¾‹:**
```
tenant123/library/user456/lib789/feedback/2025/08/feedback_abc123.json
```

## éŸ³å£°æ©Ÿèƒ½ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼

### éŸ³å£°éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«
**ãƒ‘ã‚¹å½¢å¼:**
```
{tenant_id}/audio/{user_id}/{audio_session_id}/recordings/yyyy/mm/dd/{recording_id}_audio.wav
```
**ä¾‹:**
```
tenant123/audio/user456/session789/recordings/2025/08/05/rec001_audio.wav
```

### éŸ³å£°æ–‡å­—èµ·ã“ã—
**ãƒ‘ã‚¹å½¢å¼:**
```
{tenant_id}/audio/{user_id}/{audio_session_id}/transcriptions/yyyy/mm/dd/{recording_id}_transcript.json
```
**ä¾‹:**
```
tenant123/audio/user456/session789/transcriptions/2025/08/05/rec001_transcript.json
```

**transcript.jsonå†…å®¹:**
```json
{
  "recording_id": "rec001",
  "audio_session_id": "session789",
  "user_id": "user456",
  "timestamp": "2025-08-05T14:30:00Z",
  "duration_seconds": 120,
  "language": "ja-JP",
  "model": "whisper-large-v3",
  "transcript": "æ–‡å­—èµ·ã“ã—ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ...",
  "confidence": 0.95,
  "segments": [
    {
      "start": 0.0,
      "end": 5.2,
      "text": "ã“ã‚“ã«ã¡ã¯",
      "confidence": 0.98
    }
  ]
}
```

### éŸ³å£°åˆæˆï¼ˆTTSï¼‰
**ãƒ‘ã‚¹å½¢å¼:**
```
{tenant_id}/audio/{user_id}/{audio_session_id}/tts/yyyy/mm/dd/{tts_id}_speech.mp3
```
**ä¾‹:**
```
tenant123/audio/user456/session789/tts/2025/08/05/tts001_speech.mp3
```

## å®Ÿè£…ä¾‹

### Pythonå®Ÿè£…ï¼ˆãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜ï¼‰
```python
async def save_chat_message(tenant_id: str, user_id: str, room_id: str, message: dict):
    """ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’BlobStorage/S3ã«ä¿å­˜"""
    import json
    from datetime import datetime
    from services.storage_service import storage_service
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ã‚­ãƒ¼ã®ç”Ÿæˆ
    timestamp = datetime.now()
    date_path = timestamp.strftime("%Y/%m/%d")
    time_str = timestamp.strftime("%H-%M-%S.%f")[:-3] + "Z"
    message_id = message.get('id', str(uuid.uuid4()))
    
    # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚­ãƒ¼
    storage_key = f"{tenant_id}/chat/{user_id}/{room_id}/messages/{date_path}/{time_str}-{message_id}.json"
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿
    message_data = {
        "message_id": message_id,
        "user_id": user_id,
        "room_id": room_id,
        "timestamp": timestamp.isoformat(),
        "role": message['role'],
        "content": message['content']
    }
    
    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®è¿½åŠ 
    for field in ['attachments', 'generated_images', 'context', 'agent_info']:
        if field in message:
            message_data[field] = message[field]
    
    # JSONã¨ã—ã¦ä¿å­˜
    message_json = json.dumps(message_data, ensure_ascii=False, indent=2)
    
    result = await storage_service.put_object(storage_key, message_json)
    
    if result['success']:
        print(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {storage_key}")
    else:
        raise Exception(f"ä¿å­˜å¤±æ•—: {result.get('error')}")
    
    return message_data
```

### ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¿å­˜
```python
async def save_embeddings(tenant_id: str, user_id: str, library_id: str, 
                          file_id: str, chunks_data: list):
    """ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
    import pandas as pd
    import numpy as np
    
    # Parquetå½¢å¼ã§ãƒãƒ£ãƒ³ã‚¯ã¨ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä¿å­˜
    df = pd.DataFrame(chunks_data)
    
    # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ‘ã‚¹
    embeddings_path = f"{tenant_id}/library/{user_id}/{library_id}/embeddings/{file_id}/"
    
    # chunks.parquetã¨ã—ã¦ä¿å­˜
    parquet_key = f"{embeddings_path}chunks.parquet"
    parquet_buffer = df.to_parquet()
    
    await storage_service.upload_binary(
        key=parquet_key,
        data=parquet_buffer,
        content_type='application/octet-stream'
    )
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    metadata = {
        "file_id": file_id,
        "chunk_count": len(chunks_data),
        "embedding_model": "text-embedding-3-large",
        "embedding_dimension": 3072,
        "vectorized_at": datetime.now().isoformat()
    }
    
    metadata_key = f"{embeddings_path}metadata.json"
    await storage_service.put_object(
        key=metadata_key,
        content=json.dumps(metadata, ensure_ascii=False, indent=2)
    )
    
    print(f"ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä¿å­˜: {embeddings_path}")
```

## åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¥æ¬¡ãƒãƒƒãƒï¼‰

### Parquetå½¢å¼ã§ã®åˆ†æãƒ‡ãƒ¼ã‚¿

**æ¦‚è¦ï¼š**
ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®JSONå½¢å¼ã¨ã¯åˆ¥ã«ã€åˆ†æç”¨ã«Parquetå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ—¥æ¬¡ãƒãƒƒãƒã§ç”Ÿæˆã—ã¾ã™ã€‚

**Parquetå½¢å¼ã®ãƒ¡ãƒªãƒƒãƒˆï¼š**
- **åœ§ç¸®ç‡ãŒé«˜ã„**ï¼šJSONã®10åˆ†ã®1ç¨‹åº¦ã®ã‚µã‚¤ã‚º
- **åˆ†æãŒé«˜é€Ÿ**ï¼šåˆ—æŒ‡å‘å½¢å¼ã§Athena/Synapseã«æœ€é©
- **ã‚³ã‚¹ãƒˆåŠ¹ç‡**ï¼šå¿…è¦ãªåˆ—ã®ã¿èª­ã¿è¾¼ã‚€ãŸã‚ã€ã‚¹ã‚­ãƒ£ãƒ³ã‚³ã‚¹ãƒˆãŒä½ã„

### æ—¥æ¬¡ãƒãƒƒãƒå‡¦ç†

**å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼š**
- æ¯æ—¥æ·±å¤œ2:00 UTCï¼ˆæ—¥æœ¬æ™‚é–“11:00ï¼‰
- å‰æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ

**ãƒãƒƒãƒå‡¦ç†ã®å®Ÿè£…ä¾‹ï¼š**
```python
import pandas as pd
from datetime import datetime, timedelta
import pyarrow.parquet as pq

async def daily_batch_job(tenant_id: str, target_date: str):
    """æ—¥æ¬¡ãƒãƒƒãƒã§Parquetå½¢å¼ã«å¤‰æ›"""
    
    # 1. å¯¾è±¡æ—¥ã®JSONãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åé›†
    prefix = f"{tenant_id}/chat/"
    messages = []
    
    # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¯¾è±¡æ—¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åé›†
    async for obj in storage_service.list_objects_paginated(prefix):
        if f"/{target_date}/" in obj['key'] and obj['key'].endswith('.json'):
            content = await storage_service.get_object(obj['key'])
            message = json.loads(content)
            messages.append(message)
    
    # 2. DataFrameã«å¤‰æ›
    df = pd.DataFrame(messages)
    
    # 3. åˆ†æç”¨ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
    df['date'] = pd.to_datetime(df['timestamp']).dt.date
    df['hour'] = pd.to_datetime(df['timestamp']).dt.hour
    df['message_length'] = df['content'].str.len()
    df['has_attachments'] = df['attachments'].notna()
    
    # 4. Parquetå½¢å¼ã§ä¿å­˜ï¼ˆHiveã‚¹ã‚¿ã‚¤ãƒ«ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ï¼‰
    year, month, day = target_date.split('/')
    parquet_path = f"{tenant_id}/analytics/chat/daily/year={year}/month={month}/day={day}/messages.parquet"
    
    # åœ§ç¸®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãã§ä¿å­˜
    df.to_parquet(
        parquet_path,
        compression='snappy',  # é«˜é€Ÿåœ§ç¸®
        index=False
    )
    
    # 5. é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚‚ç”Ÿæˆ
    summary_df = pd.DataFrame([{
        'date': target_date,
        'total_messages': len(df),
        'unique_users': df['user_id'].nunique(),
        'unique_rooms': df['room_id'].nunique(),
        'avg_message_length': df['message_length'].mean()
    }])
    
    summary_path = f"{tenant_id}/analytics/chat/daily/year={year}/month={month}/day={day}/summary.parquet"
    summary_df.to_parquet(summary_path)
    
    return {
        'processed_messages': len(df),
        'file_size': get_file_size(parquet_path)
    }
```

### Athena/Synapseã§ã®åˆ†æ

**ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ï¼ˆAthenaï¼‰ï¼š**
```sql
CREATE EXTERNAL TABLE IF NOT EXISTS chat_messages (
    message_id string,
    user_id string,
    room_id string,
    timestamp timestamp,
    role string,
    content string,
    message_length int,
    has_attachments boolean
)
PARTITIONED BY (
    year string,
    month string,
    day string
)
STORED AS PARQUET
LOCATION 's3://{bucket}/{tenant_id}/analytics/chat/daily/'
```

**åˆ†æã‚¯ã‚¨ãƒªä¾‹ï¼š**
```sql
-- ãƒ†ãƒŠãƒ³ãƒˆå…¨ä½“ã®æ—¥åˆ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°
SELECT 
    year, month, day,
    COUNT(*) as message_count,
    COUNT(DISTINCT user_id) as active_users,
    COUNT(DISTINCT room_id) as active_rooms
FROM chat_messages
WHERE year = '2025' AND month = '08'
GROUP BY year, month, day
ORDER BY year, month, day;

-- ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åˆ©ç”¨åˆ†æ
SELECT 
    user_id,
    DATE(timestamp) as date,
    COUNT(*) as messages,
    AVG(message_length) as avg_length,
    SUM(CASE WHEN has_attachments THEN 1 ELSE 0 END) as attachments_count
FROM chat_messages
WHERE user_id = 'user456'
    AND year = '2025' AND month = '08'
GROUP BY user_id, DATE(timestamp);

-- æ™‚é–“å¸¯åˆ¥ã®åˆ©ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
SELECT 
    hour,
    COUNT(*) as message_count,
    COUNT(DISTINCT user_id) as unique_users
FROM chat_messages
WHERE year = '2025' AND month = '08'
GROUP BY hour
ORDER BY hour;
```

### ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š

**æœˆé–“100ä¸‡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆï¼š**

| é …ç›® | æ–™é‡‘ | èª¬æ˜ |
|------|------|------|
| Lambda/Functionså®Ÿè¡Œ | $5/æœˆ | 5åˆ†Ã—30æ—¥ã®å‡¦ç† |
| S3èª­ã¿å–ã‚Š | $3/æœˆ | JSONèª­ã¿è¾¼ã¿ |
| S3æ›¸ãè¾¼ã¿ | $1/æœˆ | Parquetä¿å­˜ |
| Athenaã‚¯ã‚¨ãƒª | $5/æœˆ | 1æ—¥10ã‚¯ã‚¨ãƒªæƒ³å®š |
| **åˆè¨ˆ** | **ç´„$14/æœˆ** | |

**ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãƒã‚¤ãƒ³ãƒˆï¼š**
- Parquetåœ§ç¸®ã«ã‚ˆã‚Šä¿å­˜å®¹é‡ã‚’90%å‰Šæ¸›
- åˆ—æŒ‡å‘å½¢å¼ã«ã‚ˆã‚ŠAthenaã‚¹ã‚­ãƒ£ãƒ³é‡ã‚’å‰Šæ¸›
- ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚Šå¿…è¦ãªæ—¥ä»˜ã®ã¿ã‚¹ã‚­ãƒ£ãƒ³

## å–å¾—æ–¹æ³•

### ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å–å¾—
```python
async def get_chat_messages(tenant_id: str, user_id: str, room_id: str, limit: int = 50):
    """ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—"""
    from services.storage_service import storage_service
    
    # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
    prefix = f"{tenant_id}/chat/{user_id}/{room_id}/messages/"
    
    # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒªã‚¹ãƒˆã‚’å–å¾—
    result = await storage_service.list_objects(prefix=prefix, limit=limit)
    
    messages = []
    if result.get('success') and result.get('objects'):
        # å„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        for obj in result['objects']:
            key = obj['key']
            content = await storage_service.get_object(key)
            
            if content:
                try:
                    message = json.loads(content)
                    messages.append(message)
                except json.JSONDecodeError:
                    print(f"ãƒ‘ãƒ¼ã‚¹å¤±æ•—: {key}")
                    continue
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆï¼ˆå¤ã„é †ï¼‰
        messages.sort(key=lambda x: x.get('timestamp', ''))
    
    return messages
```

### ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ¤œç´¢
```python
async def search_embeddings(tenant_id: str, user_id: str, library_id: str, 
                           query_embedding: np.ndarray, top_k: int = 10):
    """ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œç´¢"""
    import pandas as pd
    import faiss
    
    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå†…ã®å…¨ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    prefix = f"{tenant_id}/library/{user_id}/{library_id}/embeddings/"
    result = await storage_service.list_objects(prefix=prefix)
    
    all_chunks = []
    
    for obj in result.get('objects', []):
        if obj['key'].endswith('chunks.parquet'):
            # Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            content = await storage_service.get_object(obj['key'])
            df = pd.read_parquet(io.BytesIO(content))
            all_chunks.append(df)
    
    if not all_chunks:
        return []
    
    # å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆ
    combined_df = pd.concat(all_chunks, ignore_index=True)
    embeddings = np.array(combined_df['embedding'].tolist()).astype('float32')
    
    # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
    dimension = 3072  # text-embedding-3-large
    index = faiss.IndexFlatIP(dimension)
    faiss.normalize_L2(embeddings)
    index.add(embeddings)
    
    # æ¤œç´¢å®Ÿè¡Œ
    faiss.normalize_L2(query_embedding.reshape(1, -1))
    scores, indices = index.search(query_embedding.reshape(1, -1), top_k)
    
    # çµæœã‚’è¿”ã™
    results = []
    for idx, score in zip(indices[0], scores[0]):
        chunk = combined_df.iloc[idx]
        results.append({
            'chunk_id': chunk['chunk_id'],
            'text': chunk['text'],
            'score': float(score)
        })
    
    return results
```

## KVMï¼ˆKey-Value Managementï¼‰é€£æº

### æ¦‚è¦
ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¯DynamoDB/CosmosDBï¼ˆKVMï¼‰ã§ç®¡ç†ã—ã€å®Ÿãƒ‡ãƒ¼ã‚¿ã¯BlobStorage/S3ã«ä¿å­˜ã™ã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ§‹æˆã§ã™ã€‚

### KVMã«ä¿æŒã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿

#### ãƒãƒ£ãƒƒãƒˆãƒ«ãƒ¼ãƒ ãƒ¡ã‚¿æƒ…å ±
| é …ç›®å | èª¬æ˜ | å‚™è€ƒ |
|--------|------|------|
| PK | ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚­ãƒ¼ | `TENANT#{tenant_id}#USER#{user_id}` |
| SK | ã‚½ãƒ¼ãƒˆã‚­ãƒ¼ | `CHAT#{room_id}` |
| title | ãƒãƒ£ãƒƒãƒˆã‚¿ã‚¤ãƒˆãƒ« | |
| created_at | ä½œæˆæ—¥æ™‚ | ISO 8601å½¢å¼ |
| updated_at | æ›´æ–°æ—¥æ™‚ | æœ€çµ‚ç™ºè¨€æ™‚ã«æ›´æ–° |
| message_count | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•° | |
| last_message | ç›´è¿‘ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ | æœ¬æ–‡ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ50æ–‡å­—ï¼‰ã€æ™‚åˆ»ã€é€ä¿¡è€… |
| unread_count | æœªèª­æ•° | ã‚ªãƒ—ã‚·ãƒ§ãƒ³ |
| settings | ãƒãƒ£ãƒƒãƒˆè¨­å®š | system_promptã€temperatureç­‰ |
| status | ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ | active/archived/deleted |

```python
# å®Ÿä¾‹
{
    'PK': 'TENANT#tenant123#USER#user456',
    'SK': 'CHAT#roomA',
    'title': 'ãƒŸãƒ„ã‚¤ãƒ¯ç¤¾é•·ã«ã¤ã„ã¦',
    'created_at': '2025-08-05T10:00:00Z',
    'updated_at': '2025-08-05T12:34:56Z',
    'message_count': 42,
    'last_message': {
        'text': 'è³ªå•ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™...',  # 50æ–‡å­—ã¾ã§
        'timestamp': '2025-08-05T12:34:56Z',
        'role': 'assistant'
    },
    'unread_count': 0,
    'status': 'active'
}
```

#### ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¡ã‚¿æƒ…å ±
| é …ç›®å | èª¬æ˜ | å‚™è€ƒ |
|--------|------|------|
| PK | ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚­ãƒ¼ | `TENANT#{tenant_id}#USER#{user_id}` |
| SK | ã‚½ãƒ¼ãƒˆã‚­ãƒ¼ | `LIBRARY#{library_id}` |
| name | ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå | |
| description | èª¬æ˜ | |
| created_at | ä½œæˆæ—¥æ™‚ | |
| updated_at | æ›´æ–°æ—¥æ™‚ | |
| file_count | ãƒ•ã‚¡ã‚¤ãƒ«æ•° | |
| total_chunks | ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ•° | |
| visibility | å…¬é–‹ç¯„å›² | private/shared/public |
| vector_status | ãƒ™ã‚¯ãƒˆãƒ«åŒ–é€²æ— | pending/processing/completed/failed |

#### éŸ³å£°ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¡ã‚¿æƒ…å ±
| é …ç›®å | èª¬æ˜ | å‚™è€ƒ |
|--------|------|------|
| PK | ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚­ãƒ¼ | `TENANT#{tenant_id}#USER#{user_id}` |
| SK | ã‚½ãƒ¼ãƒˆã‚­ãƒ¼ | `AUDIO#{audio_session_id}` |
| created_at | é–‹å§‹æ—¥æ™‚ | |
| updated_at | æœ€çµ‚æ›´æ–° | |
| total_recordings | éŒ²éŸ³æ•° | |
| transcription_status | æ–‡å­—èµ·ã“ã—é€²æ— | pending/processing/completed |

### KVMã«ä¿å­˜ã—ãªã„ã‚‚ã®
- âŒ ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æœ¬æ–‡
- âŒ ãƒ•ã‚¡ã‚¤ãƒ«æœ¬ä½“
- âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æœ¬ä½“
- âŒ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿æœ¬ä½“
- âŒ ç”»åƒãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæœ¬ä½“

### é€£æºé‹ç”¨ãƒ•ãƒ­ãƒ¼

#### æ–°è¦ãƒãƒ£ãƒƒãƒˆãƒ«ãƒ¼ãƒ ä½œæˆæ™‚
```python
# 1. KVMã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç™»éŒ²
await kvm.put_item({
    'PK': f'TENANT#{tenant_id}#USER#{user_id}',
    'SK': f'CHAT#{room_id}',
    'title': title,
    'created_at': datetime.now().isoformat(),
    'updated_at': datetime.now().isoformat(),
    'message_count': 0,
    'status': 'active'
})

# 2. ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™ï¼ˆåˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ™‚ã§ã‚‚å¯ï¼‰
```

#### ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æŠ•ç¨¿æ™‚
```python
# 1. ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜
message_key = f"{tenant_id}/chat/{user_id}/{room_id}/messages/{date_path}/{time}-{msg_id}.json"
await storage.put_object(message_key, message_json)

# 2. KVMã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°ï¼ˆatomicï¼‰
await kvm.update_item(
    Key={'PK': f'TENANT#{tenant_id}#USER#{user_id}', 'SK': f'CHAT#{room_id}'},
    UpdateExpression='SET updated_at = :now, message_count = message_count + :inc, last_message = :msg',
    ExpressionAttributeValues={
        ':now': datetime.now().isoformat(),
        ':inc': 1,
        ':msg': {
            'text': content[:50] + '...' if len(content) > 50 else content,
            'timestamp': datetime.now().isoformat(),
            'role': role
        }
    }
)
```

#### ãƒãƒ£ãƒƒãƒˆä¸€è¦§å–å¾—æ™‚
```python
# KVMã‹ã‚‰é«˜é€Ÿå–å¾—ï¼ˆã€œ10msï¼‰
response = await kvm.query(
    KeyConditionExpression='PK = :pk AND begins_with(SK, :sk)',
    ExpressionAttributeValues={
        ':pk': f'TENANT#{tenant_id}#USER#{user_id}',
        ':sk': 'CHAT#'
    },
    ScanIndexForward=False,  # æ–°ã—ã„é †
    Limit=100
)
# last_messageã‚„unread_countãŒå³åº§ã«å–å¾—å¯èƒ½
```

#### ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´å–å¾—æ™‚
```python
# ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰å¿…è¦ãªåˆ†ã ã‘å–å¾—ï¼ˆã€œ200msï¼‰
prefix = f"{tenant_id}/chat/{user_id}/{room_id}/messages/"
messages = await storage.list_and_get_objects(prefix, limit=50)
```

## åˆ¶é™äº‹é …

### ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™
- **ãƒãƒ£ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: æœ€å¤§10MB
- **ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ•ã‚¡ã‚¤ãƒ«**: æœ€å¤§50MB
- **éŸ³å£°éŒ²éŸ³**: æœ€å¤§30åˆ†ï¼ˆç´„300MBï¼‰
- **ç”Ÿæˆç”»åƒ**: DALL-E 3ã®åˆ¶é™ã«æº–æ‹ ï¼ˆ1024x1024ï¼‰
- **ã‚µãƒ ãƒã‚¤ãƒ«**: æœ€å¤§200x200ãƒ”ã‚¯ã‚»ãƒ«ã€JPEGå½¢å¼

### ãƒ¬ãƒ¼ãƒˆåˆ¶é™
- **1åˆ†ã‚ãŸã‚Šã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°**: 10
- **1æ™‚é–“ã‚ãŸã‚Šã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°**: 100
- **1æ™‚é–“ã‚ãŸã‚Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ•°**: 20
- **OpenAI Embedding API**: 3,000 RPM / 1,000,000 TPM

## æ³¨æ„äº‹é …

### ã‚„ã£ã¦ã¯ã„ã‘ãªã„ã“ã¨
1. **TinyDBã®ä½¿ç”¨** - é–‹ç™ºç’°å¢ƒã§ã‚‚ä½¿ç”¨ç¦æ­¢
2. **DynamoDBã¸ã®ç›´æ¥ä¿å­˜** - ãƒ‡ãƒ¼ã‚¿æœ¬ä½“ã¯ä¿å­˜ã—ãªã„ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
3. **ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹ä¿å­˜å…ˆã®åˆ†å²** - å…¨ã¦ä¸€å¾‹BlobStorage/S3ã¸
4. **ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆ** - æœ€å¤§500ä»¶ç¨‹åº¦ãªã®ã§ä¸è¦

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®
- ãƒãƒ£ãƒƒãƒˆãƒ«ãƒ¼ãƒ æ¯ã®æœ€å¤§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ï¼šç´„500ä»¶
- ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ¯ã®æ¨å¥¨ãƒãƒ£ãƒ³ã‚¯æ•°ï¼šã€œ50,000ä»¶ï¼ˆFAISSã®å ´åˆï¼‰
- å¤§è¦æ¨¡ãªå ´åˆã¯Pinecone/Weaviateãªã©ã®å°‚ç”¨ãƒ™ã‚¯ãƒˆãƒ«DBã‚’æ¤œè¨

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
- ãƒ†ãƒŠãƒ³ãƒˆã”ã¨ã«ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹`{tenant_id}/`ã§ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã«ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹`{user_id}/`ã§ã•ã‚‰ã«åˆ¶é™
- ç½²åä»˜ãURL/SASãƒˆãƒ¼ã‚¯ãƒ³ã§ä¸€æ™‚çš„ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯
- ã‚¯ãƒ­ã‚¹ãƒ†ãƒŠãƒ³ãƒˆã‚¢ã‚¯ã‚»ã‚¹ã¯å®Œå…¨ã«ç¦æ­¢
- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¦ã‚¤ãƒ«ã‚¹ã‚¹ã‚­ãƒ£ãƒ³æ¨å¥¨